<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Distributed Systems on Quang Hugo</title><link>https://quanghugo.pages.dev/categories/distributed-systems/</link><description>Recent content in Distributed Systems on Quang Hugo</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 10 Jan 2026 02:30:00 +0000</lastBuildDate><atom:link href="https://quanghugo.pages.dev/categories/distributed-systems/index.xml" rel="self" type="application/rss+xml"/><item><title>The Status Order Fail During Rolling Deployments - PART2</title><link>https://quanghugo.pages.dev/p/rolling-production-p2/</link><pubDate>Sat, 10 Jan 2026 02:30:00 +0000</pubDate><guid>https://quanghugo.pages.dev/p/rolling-production-p2/</guid><description>&lt;h2 id="the-problem-quick-recap"&gt;The Problem (Quick Recap)
&lt;/h2&gt;&lt;p&gt;In our &lt;strong&gt;&lt;a class="link" href="https://quanghugo.pages.dev/p/rolling-production-p1" &gt;previous article&lt;/a&gt;&lt;/strong&gt;, I explored a critical issue: when servers restart during deployment, in-memory timeout timers are lost, causing orders to get stuck in pending status indefinitely.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The scenario&lt;/strong&gt;: A customer places an order and the system starts a &lt;strong&gt;60s&lt;/strong&gt; timer. If payment isn&amp;rsquo;t confirmed within &lt;strong&gt;60s&lt;/strong&gt;, the order should automatically timeout. But if the server restarts at &lt;strong&gt;second 45&lt;/strong&gt;, that timer disappears—and the order &lt;em&gt;never times out&lt;/em&gt;. The customer sees &lt;strong&gt;&amp;ldquo;Order failed&amp;rdquo;&lt;/strong&gt; on their screen, but the backend still thinks the order is &lt;strong&gt;PENDING&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This creates confusion, duplicate orders, and requires manual cleanup.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="the-core-insight"&gt;The Core Insight
&lt;/h2&gt;&lt;p&gt;The problem isn&amp;rsquo;t with timers themselves—it&amp;rsquo;s where I store the timer information. When I store timeout information &lt;strong&gt;in the application&amp;rsquo;s memory&lt;/strong&gt;, it disappears when the application restarts.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The solution? Move timeout tracking outside the application&lt;/strong&gt; into a shared storage system that survives restarts.&lt;/p&gt;
&lt;h3 id="the-calendar-analogy"&gt;The Calendar Analogy
&lt;/h3&gt;&lt;p&gt;Imagine two ways of tracking deadlines:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Old Approach (In-Memory Timer)&lt;/strong&gt;&lt;br&gt;
Each employee has a desk calendar. When they mark &amp;ldquo;Review document by &lt;strong&gt;3 PM&lt;/strong&gt;,&amp;rdquo; only they know about it. If they go home sick, no one else can see that deadline—it&amp;rsquo;s lost.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;New Approach (Shared Storage)&lt;/strong&gt;&lt;br&gt;
The team uses a shared wall calendar in the office. When anyone marks &amp;ldquo;Review document by &lt;strong&gt;3 PM&lt;/strong&gt;,&amp;rdquo; everyone can see it. If one person is &lt;strong&gt;unavailable&lt;/strong&gt;, someone else can check the calendar and handle the task.&lt;/p&gt;
&lt;p&gt;This is exactly what I&amp;rsquo;m doing: moving from individual &amp;ldquo;desk calendars&amp;rdquo; (&lt;strong&gt;in-memory timers&lt;/strong&gt;) to a &amp;ldquo;shared wall calendar&amp;rdquo; (&lt;strong&gt;Redis&lt;/strong&gt;) that all servers can access.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="the-solution-three-key-components"&gt;The Solution: Three Key Components
&lt;/h2&gt;&lt;p&gt;Our solution uses three simple concepts that work together:&lt;/p&gt;
&lt;h3 id="1-the-shared-timeout-list"&gt;1. The Shared Timeout List
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What it is&lt;/strong&gt;: A shared list where I writes down every timeout and when it should happen, sorted by time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How it works&lt;/strong&gt;: When an order is created, instead of setting a timer in the server&amp;rsquo;s memory, I write to this shared list: &amp;ldquo;Order #12345 should timeout at 2:30:15 PM.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why it survives restarts&lt;/strong&gt;: This list lives in a database-like storage system (Redis) that&amp;rsquo;s separate from our application servers. When a &lt;strong&gt;server restarts, the list is still there&lt;/strong&gt;, untouched.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Analogy&lt;/strong&gt;: Like a shared to-do list on the wall, sorted by deadline. Everyone can see it, and it doesn&amp;rsquo;t disappear when someone leaves the room.&lt;/p&gt;
&lt;h3 id="2-the-worker-pattern"&gt;2. The Worker Pattern
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What it is&lt;/strong&gt;: Every server regularly checks the shared timeout list to find tasks that are ready to be processed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How it works&lt;/strong&gt;: Every second, each server asks: &lt;em&gt;&amp;ldquo;Are there any timeouts in the list that have already passed?&amp;rdquo;&lt;/em&gt; If it finds any, it processes them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why it&amp;rsquo;s resilient&lt;/strong&gt;: If &lt;strong&gt;one server goes down, the other servers keep checking&lt;/strong&gt; the list. No single server is responsible for any specific timeout—they all share the work.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Analogy&lt;/strong&gt;: Like multiple security guards on patrol. They all check the same checklist every few minutes. If one guard goes on break, the others keep checking—nothing gets missed.&lt;/p&gt;
&lt;h3 id="3-the-lock-preventing-duplicates"&gt;3. The Lock (Preventing Duplicates)
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What it is&lt;/strong&gt;: A mechanism to ensure only one server processes each timeout, even though multiple servers are checking the list.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How it works&lt;/strong&gt;: When &lt;strong&gt;Server A&lt;/strong&gt; sees an expired timeout, it tries to &lt;em&gt;&amp;ldquo;grab&amp;rdquo;&lt;/em&gt; it by placing a lock. If it succeeds, it processes the timeout. If &lt;strong&gt;Server B&lt;/strong&gt; tries to grab the same timeout a moment later, it &lt;strong&gt;sees the lock&lt;/strong&gt; and skips it—knowing &lt;strong&gt;Server A&lt;/strong&gt; is already handling it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why it&amp;rsquo;s necessary&lt;/strong&gt;: Without locks, &lt;strong&gt;Server A and Server B might both process&lt;/strong&gt; the same timeout, sending two &amp;ldquo;Order timed out&amp;rdquo; notifications to the customer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Analogy&lt;/strong&gt;: Like task cards on a Kanban board. When you start working on a task, you move the card to &lt;strong&gt;&amp;ldquo;In Progress&amp;rdquo;&lt;/strong&gt;.Other team members see it&amp;rsquo;s being worked on and don&amp;rsquo;t &lt;em&gt;duplicate&lt;/em&gt; the effort.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="how-it-all-works-together"&gt;How It All Works Together
&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s walk through a complete timeout lifecycle:&lt;/p&gt;
&lt;pre class="mermaid"&gt;
flowchart TB
Order[Customer Places Order]
Write[Write to Shared List:&amp;lt;br/&amp;gt;Order 12345 timeout at 2:30 PM]
SharedList[(Shared Timeout List&amp;lt;br/&amp;gt;in Redis)]
Order --&amp;gt; Write
Write --&amp;gt; SharedList
subgraph AllServers[All Servers Working Together]
ServerA[Server A checks list&amp;lt;br/&amp;gt;every second]
ServerB[Server B checks list&amp;lt;br/&amp;gt;every second]
ServerC[Server C checks list&amp;lt;br/&amp;gt;every second]
end
SharedList -.-&amp;gt;|poll| ServerA
SharedList -.-&amp;gt;|poll| ServerB
SharedList -.-&amp;gt;|poll| ServerC
ServerA --&amp;gt; FindExpired[Found expired timeout:&amp;lt;br/&amp;gt;Order 12345]
FindExpired --&amp;gt; TryLock{Try to lock&amp;lt;br/&amp;gt;Order 12345}
TryLock --&amp;gt;|Lock successful| Process[Process timeout:&amp;lt;br/&amp;gt;Update order status&amp;lt;br/&amp;gt;Notify customer]
TryLock --&amp;gt;|Lock failed| Skip[Skip - another&amp;lt;br/&amp;gt;server handling it]
Process --&amp;gt; RemoveFromList[Remove from shared list]
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Step-by-step explanation&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Order Created&lt;/strong&gt;: Customer places Order &lt;strong&gt;#12345&lt;/strong&gt;. The system writes to the shared list: &amp;ldquo;Order #12345, &lt;strong&gt;timeout&lt;/strong&gt; at &lt;strong&gt;2:30:15 PM&lt;/strong&gt;&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Servers Monitor&lt;/strong&gt;: All servers (A, B, C) independently check the shared list every second, asking &lt;em&gt;&amp;ldquo;Any timeouts past their deadline?&amp;rdquo;&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Timeout Found&lt;/strong&gt;: At &lt;strong&gt;2:30:16 PM&lt;/strong&gt;, &lt;strong&gt;Server A&lt;/strong&gt; checks and finds Order &lt;em&gt;#12345&lt;/em&gt; is past its deadline (by 1 second)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Lock Attempt&lt;/strong&gt;: Server A tries to &lt;em&gt;&amp;ldquo;lock&amp;rdquo;&lt;/em&gt; Order &lt;strong&gt;#12345&lt;/strong&gt;. If successful, it proceeds. If another server locked it first, Server A skips it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Process Timeout&lt;/strong&gt;: &lt;strong&gt;Server A&lt;/strong&gt; updates the order status to &lt;strong&gt;&amp;ldquo;Payment Timeout&amp;rdquo;&lt;/strong&gt; and sends a notification to the customer&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Clean Up&lt;/strong&gt;: Server A &lt;strong&gt;removes&lt;/strong&gt; Order &lt;strong&gt;#12345&lt;/strong&gt; from the shared list so no other server tries to process it&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id="what-happens-during-deployment"&gt;What Happens During Deployment
&lt;/h2&gt;&lt;p&gt;This is where the new approach really shines. Let&amp;rsquo;s compare the old and new systems during a rolling deployment:&lt;/p&gt;
&lt;h3 id="old-system-in-memory-timer"&gt;Old System: In-Memory Timer
&lt;/h3&gt;&lt;pre class="mermaid"&gt;
sequenceDiagram
participant Customer
participant ServerA
participant Kubernetes
participant Database
Customer-&amp;gt;&amp;gt;ServerA: Place order
ServerA-&amp;gt;&amp;gt;Database: Save order (Pending)
ServerA-&amp;gt;&amp;gt;ServerA: Start 60s timer&amp;lt;br/&amp;gt;in memory
Note over ServerA: Timer counting: 45s...44s...43s...
Kubernetes-&amp;gt;&amp;gt;ServerA: Deploy new version&amp;lt;br/&amp;gt;(restart server)
ServerA-&amp;gt;&amp;gt;ServerA: Server shuts down
Note over ServerA: ❌ Timer lost!
Note over Database: Order stuck in Pending
Note over Customer: App shows timeout&amp;lt;br/&amp;gt;but backend is inconsistent
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;What goes wrong&lt;/strong&gt;: The timer lives only in &lt;strong&gt;Server A&amp;rsquo;s memory&lt;/strong&gt;. When Server A &lt;strong&gt;restarts&lt;/strong&gt;, the timer is &lt;strong&gt;gone&lt;/strong&gt;. Order &lt;em&gt;#12345 never times ou&lt;/em&gt;t.&lt;/p&gt;
&lt;h3 id="new-system-shared-timeout-list"&gt;New System: Shared Timeout List
&lt;/h3&gt;&lt;pre class="mermaid"&gt;
sequenceDiagram
participant Customer
participant ServerA
participant SharedList as Shared Timeout List
participant Kubernetes
participant ServerB
participant Database
Customer-&amp;gt;&amp;gt;ServerA: Place order
ServerA-&amp;gt;&amp;gt;Database: Save order (Pending)
ServerA-&amp;gt;&amp;gt;SharedList: Write: Order 12345&amp;lt;br/&amp;gt;timeout at 2:30 PM
Note over SharedList: ✓ Stored safely
Kubernetes-&amp;gt;&amp;gt;ServerA: Deploy new version&amp;lt;br/&amp;gt;(restart server)
ServerA-&amp;gt;&amp;gt;ServerA: Server shuts down
Note over SharedList: ✓ List still intact!
ServerB-&amp;gt;&amp;gt;SharedList: Check for expired timeouts
SharedList--&amp;gt;&amp;gt;ServerB: Order 12345 expired
ServerB-&amp;gt;&amp;gt;ServerB: Lock and process timeout
ServerB-&amp;gt;&amp;gt;Database: Update order (Timeout)
ServerB-&amp;gt;&amp;gt;Customer: Notify: Payment timeout
ServerB-&amp;gt;&amp;gt;SharedList: Remove Order 12345
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;What goes right&lt;/strong&gt;: The timeout information lives in the shared list, &lt;em&gt;not in Server A&amp;rsquo;s memory&lt;/em&gt;. When Server A restarts, Server B (still running) finds the expired timeout and processes it. The customer gets the correct notification, and the order status is updated properly.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="trade-offs-and-considerations"&gt;Trade-offs and Considerations
&lt;/h2&gt;&lt;p&gt;No solution is perfect. Here&amp;rsquo;s what I gained and what I accepted:&lt;/p&gt;
&lt;h3 id="-benefits"&gt;✅ Benefits
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Reliability&lt;/strong&gt;: Timeouts survive server restarts. During deployments, maintenance, or unexpected crashes, no timeout is lost.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: Works across any number of servers. Adding more servers means more workers checking the list—better throughput.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: The system state stays consistent. No more &amp;ldquo;ghost orders&amp;rdquo; that customers think failed but are still active in the backend.&lt;/p&gt;
&lt;h3 id="-trade-offs"&gt;⚖️ Trade-offs
&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Small Processing Delay&lt;/strong&gt;: Instead of processing timeouts at exactly 60.000 seconds, I process them within ~61 seconds (60 seconds + up to 1 second for the worker to check the list).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s acceptable&lt;/strong&gt;: For a 60-second timeout, a 1-second variance is imperceptible to customers. The business requirement is &amp;ldquo;notify within reasonable time,&amp;rdquo; not &amp;ldquo;exactly at 60 seconds.&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Dependency on Shared Storage&lt;/strong&gt;: The system now depends on Redis (the shared storage) being available.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s acceptable&lt;/strong&gt;: Redis is already a critical component for many features (caching, sessions). It&amp;rsquo;s highly reliable with built-in redundancy. If Redis goes down, I have bigger problems than timeouts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Eventual Processing&lt;/strong&gt;: There&amp;rsquo;s a brief window where a timeout has technically expired but hasn&amp;rsquo;t been processed yet (while waiting for the next worker check).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s acceptable&lt;/strong&gt;: The database check is idempotent—before processing, I verify the order is still in &lt;strong&gt;PENDING&lt;/strong&gt; status. If a payment came through at the last second, I skip the timeout.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id="real-world-impact"&gt;Real-World Impact
&lt;/h2&gt;&lt;p&gt;After deploying this solution to production:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Metric&lt;/th&gt;
&lt;th&gt;Before (In-Memory)&lt;/th&gt;
&lt;th&gt;After (Shared List)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Orders stuck during deployment&lt;/td&gt;
&lt;td&gt;5-10 per day&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Average delay for stuck orders&lt;/td&gt;
&lt;td&gt;2-5 minutes&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Manual cleanup required&lt;/td&gt;
&lt;td&gt;Daily&lt;/td&gt;
&lt;td&gt;Never&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Customer complaints about &amp;ldquo;ghost orders&amp;rdquo;&lt;/td&gt;
&lt;td&gt;Weekly&lt;/td&gt;
&lt;td&gt;None&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Timeout processing accuracy&lt;/td&gt;
&lt;td&gt;Exact (but fails on restart)&lt;/td&gt;
&lt;td&gt;Within 1 second (always works)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The numbers speak for themselves. The small trade-off (1-second delay) is completely invisible to users, while the benefit (zero stuck orders) dramatically improves both user experience and operational efficiency.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="key-takeaways"&gt;Key Takeaways
&lt;/h2&gt;&lt;p&gt;This solution teaches us several important principles that apply beyond just timeout handling:&lt;/p&gt;
&lt;h3 id="1-persistent-state-survives-restarts"&gt;1. Persistent State Survives Restarts
&lt;/h3&gt;&lt;p&gt;When critical information lives only in application memory, it disappears during restarts. Moving it to external, persistent storage makes it durable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Applies to&lt;/strong&gt;: Background jobs, scheduled tasks, workflow state, temporary data that users depend on.&lt;/p&gt;
&lt;h3 id="2-shared-storage-enables-distributed-work"&gt;2. Shared Storage Enables Distributed Work
&lt;/h3&gt;&lt;p&gt;When multiple servers can see the same work queue, they can share the load and provide redundancy. If one fails, others pick up the slack.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Applies to&lt;/strong&gt;: Task queues, job scheduling, event processing, any work that can be distributed.&lt;/p&gt;
&lt;h3 id="3-locks-prevent-duplicate-processing"&gt;3. Locks Prevent Duplicate Processing
&lt;/h3&gt;&lt;p&gt;In distributed systems where multiple workers process the same queue, coordination (locks) ensures each item is processed exactly once.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Applies to&lt;/strong&gt;: Payment processing, notification sending, any operation that shouldn&amp;rsquo;t happen twice.&lt;/p&gt;
&lt;h3 id="4-small-delays-are-often-acceptable"&gt;4. Small Delays Are Often Acceptable
&lt;/h3&gt;&lt;p&gt;Perfect timing (exactly 60.000 seconds) often isn&amp;rsquo;t necessary. &amp;ldquo;Close enough&amp;rdquo; (60-61 seconds) is usually fine if it makes the system more reliable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Applies to&lt;/strong&gt;: Most user-facing features prioritize reliability over microsecond precision.&lt;/p&gt;
&lt;h3 id="5-idempotency-handles-edge-cases"&gt;5. Idempotency Handles Edge Cases
&lt;/h3&gt;&lt;p&gt;By checking current state before acting (&amp;quot;&lt;em&gt;Is the order still pending?&lt;/em&gt;&amp;quot;), the system gracefully handles race conditions and ensures consistency even if something processes twice.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Applies to&lt;/strong&gt;: Any distributed operation, retry logic, eventual consistency scenarios.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="conclusion"&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;The journey from in-memory timers to shared timeout lists teaches a broader lesson: &lt;strong&gt;in distributed systems, shared persistent state is more reliable than isolated in-memory state&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;While the old approach (spawn a thread, sleep, execute callback) is simpler to code, it breaks down under real-world conditions: deployments, restarts, scaling up or down. The new approach requires more infrastructure (Redis, workers, locks) but handles these conditions gracefully.&lt;/p&gt;
&lt;p&gt;For systems running in production—especially in containerized environments like Kubernetes where restarts are routine—this architectural pattern is essential. Whether you&amp;rsquo;re building e-commerce, ride-sharing, job scheduling, or any system with time-dependent logic, the same principles apply:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Persist critical state&lt;/strong&gt; outside your application&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Distribute the work&lt;/strong&gt; across multiple workers&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Coordinate with locks&lt;/strong&gt; to prevent duplicates&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Accept small delays&lt;/strong&gt; for much better reliability&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The result is a system that works consistently, even when individual servers come and go—which is exactly what modern cloud infrastructure demands.&lt;/p&gt;</description></item><item><title>The Status Order Fail During Rolling Deployments - PART1</title><link>https://quanghugo.pages.dev/p/rolling-production-p1/</link><pubDate>Tue, 30 Dec 2025 00:00:00 +0000</pubDate><guid>https://quanghugo.pages.dev/p/rolling-production-p1/</guid><description>&lt;h2 id="the-problem"&gt;The Problem
&lt;/h2&gt;&lt;p&gt;Systems that rely on in-memory timeout mechanisms can encounter critical issues during rolling deployments. When a deployment occurs while timeout operations are in progress, these operations may be terminated before completion, leading to state inconsistencies and system failures.&lt;/p&gt;
&lt;p&gt;Consider, for example, an e-commerce order processing system. When a customer places an order, the system attempts to process their payment confirmation. The system enforces a strict 60-second timeout window to receive payment confirmation. If payment confirmation is not received within this timeframe, the system should automatically return a &amp;ldquo;Payment Timeout&amp;rdquo; response and update the order status accordingly.&lt;/p&gt;
&lt;p&gt;Under normal operating conditions, this mechanism works perfectly. However, during rolling deployments, some orders may exceed their timeout limits by 2-3x, creating a dangerous inconsistency between what the client displayed and the actual backend state. Orders that should have timed out after 60 seconds may remain in a &lt;strong&gt;PENDING_PAYMENT&lt;/strong&gt; status for 120-180 seconds, causing inconsistent system behavior and user confusion.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="understanding-the-system-architecture"&gt;Understanding the System Architecture
&lt;/h2&gt;&lt;h3 id="virtual-threads-overview"&gt;Virtual Threads Overview
&lt;/h3&gt;&lt;p&gt;Many systems leverage &lt;strong&gt;Java Virtual Threads&lt;/strong&gt; (introduced in Java 19 as a preview and finalized in Java 21) to handle timeout mechanisms efficiently. Virtual threads are lightweight threads managed by the Java Virtual Machine, allowing applications to create millions of threads without the overhead of traditional platform threads.&lt;/p&gt;
&lt;p&gt;For timeout implementations, systems typically spawn a virtual thread that sleeps for the duration of the timeout period (e.g., 60 seconds). When the timeout expires, the thread executes a callback function that handles the timeout scenario.&lt;/p&gt;
&lt;h3 id="the-timeout-mechanism"&gt;The Timeout Mechanism
&lt;/h3&gt;&lt;p&gt;To illustrate this, let&amp;rsquo;s examine an e-commerce order processing system. In such a system, the timeout flow works as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Order Creation&lt;/strong&gt;: When a customer places an order, the system creates an order record with status &lt;code&gt;PENDING_PAYMENT&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Timer Initialization&lt;/strong&gt;: A virtual thread is spawned to handle the timeout countdown&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Payment Processing&lt;/strong&gt;: The system attempts to process and confirm the payment&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Success Path&lt;/strong&gt;: If payment is confirmed, the timer thread is interrupted and the order status is updated to &lt;code&gt;CONFIRMED&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Timeout Path&lt;/strong&gt;: If payment confirmation is not received within 60 seconds, the timer thread executes the timeout callback, updating the order status to &lt;code&gt;PAYMENT_TIMEOUT&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This design works reliably in stable environments, but reveals a critical flaw during deployment scenarios.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="the-deployment-failure-scenario"&gt;The Deployment Failure Scenario
&lt;/h2&gt;&lt;p&gt;During a rolling deployment in Kubernetes, systems using in-memory timeout mechanisms can experience failures. Consider a scenario where an e-commerce system is processing orders during a deployment. The following sequence of events occurs:&lt;/p&gt;
&lt;pre class="mermaid"&gt;
sequenceDiagram
participant User as Customer
participant Pod as Service Pod
participant K8s as Kubernetes
participant DB as Database
User-&amp;gt;&amp;gt;Pod: Place order request
Pod-&amp;gt;&amp;gt;DB: Create order (PENDING_PAYMENT)
Pod-&amp;gt;&amp;gt;Pod: Spawn virtual thread&amp;lt;br/&amp;gt;sleep(60s) → timeout callback
Note over Pod: Timer counting: 59s, 58s, 57s...
K8s-&amp;gt;&amp;gt;Pod: SIGTERM signal
Pod-&amp;gt;&amp;gt;Pod: JVM shutdown initiated
Pod-&amp;gt;&amp;gt;Pod: All threads terminated
Note over Pod: Timeout thread killed&amp;lt;br/&amp;gt;before callback executes
Pod-&amp;gt;&amp;gt;DB: Pod terminates
Note over DB: Order remains in PENDING_PAYMENT state
Note over User: Client shows timeout&amp;lt;br/&amp;gt;Backend still waiting
&lt;/pre&gt;
&lt;h3 id="what-happens-during-rolling-deployment"&gt;What Happens During Rolling Deployment
&lt;/h3&gt;&lt;p&gt;In an e-commerce system, this failure scenario unfolds as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Normal Operation&lt;/strong&gt;: An order is created and a virtual thread starts the 60-second countdown&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deployment Triggered&lt;/strong&gt;: Kubernetes initiates a rolling deployment, sending a &lt;code&gt;SIGTERM&lt;/code&gt; signal to the pod&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JVM Shutdown&lt;/strong&gt;: The Java Virtual Machine begins its shutdown sequence&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Thread Termination&lt;/strong&gt;: All threads, including the timeout virtual thread, are terminated immediately&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Callback Never Executes&lt;/strong&gt;: The timeout callback that should update the order status never fires&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;State Inconsistency&lt;/strong&gt;: The order remains in &lt;code&gt;PENDING_PAYMENT&lt;/code&gt; status indefinitely, while the client has already shown a timeout error&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="code-example"&gt;Code Example
&lt;/h3&gt;&lt;p&gt;An example implementation in an e-commerce system might look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;div class="chroma"&gt;
&lt;table class="lntable"&gt;&lt;tr&gt;&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code&gt;&lt;span class="lnt"&gt; 1
&lt;/span&gt;&lt;span class="lnt"&gt; 2
&lt;/span&gt;&lt;span class="lnt"&gt; 3
&lt;/span&gt;&lt;span class="lnt"&gt; 4
&lt;/span&gt;&lt;span class="lnt"&gt; 5
&lt;/span&gt;&lt;span class="lnt"&gt; 6
&lt;/span&gt;&lt;span class="lnt"&gt; 7
&lt;/span&gt;&lt;span class="lnt"&gt; 8
&lt;/span&gt;&lt;span class="lnt"&gt; 9
&lt;/span&gt;&lt;span class="lnt"&gt;10
&lt;/span&gt;&lt;span class="lnt"&gt;11
&lt;/span&gt;&lt;span class="lnt"&gt;12
&lt;/span&gt;&lt;span class="lnt"&gt;13
&lt;/span&gt;&lt;span class="lnt"&gt;14
&lt;/span&gt;&lt;span class="lnt"&gt;15
&lt;/span&gt;&lt;span class="lnt"&gt;16
&lt;/span&gt;&lt;span class="lnt"&gt;17
&lt;/span&gt;&lt;span class="lnt"&gt;18
&lt;/span&gt;&lt;span class="lnt"&gt;19
&lt;/span&gt;&lt;span class="lnt"&gt;20
&lt;/span&gt;&lt;span class="lnt"&gt;21
&lt;/span&gt;&lt;span class="lnt"&gt;22
&lt;/span&gt;&lt;span class="lnt"&gt;23
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class="lntd"&gt;
&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-java" data-lang="java"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kd"&gt;public&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;createOrder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OrderRequest&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;// Create order in database&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Order&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;order&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;orderRepository&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;new&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Order&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Status&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;PENDING_PAYMENT&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;// Spawn virtual thread for timeout&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;ofVirtual&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="na"&gt;start&lt;/span&gt;&lt;span class="p"&gt;(()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;60_000&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;// 60 seconds&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;handlePaymentTimeout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;order&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getId&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;catch&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;InterruptedException&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;// Payment confirmed, timer interrupted - this is the happy path&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;currentThread&lt;/span&gt;&lt;span class="p"&gt;().&lt;/span&gt;&lt;span class="na"&gt;interrupt&lt;/span&gt;&lt;span class="p"&gt;();&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;});&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;// Attempt to process payment&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;processPaymentConfirmation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;order&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;getId&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kd"&gt;private&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;void&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;handlePaymentTimeout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Long&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;orderId&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;// This callback never executes if pod is killed during deployment&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;orderRepository&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;updateStatus&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;orderId&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Status&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="na"&gt;PAYMENT_TIMEOUT&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;The critical issue is that &lt;code&gt;handlePaymentTimeout()&lt;/code&gt; never executes if the JVM is terminated before the 60-second sleep completes. This problem is not unique to e-commerce systems—any system relying on in-memory timeout mechanisms faces the same risk.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="why-this-is-dangerous"&gt;Why This Is Dangerous
&lt;/h2&gt;&lt;p&gt;This failure mode creates a dangerous inconsistency between client and server states. For instance, in an e-commerce system, this might manifest as:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Client View&lt;/th&gt;
&lt;th&gt;Backend Reality&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Shows &amp;ldquo;Order failed&amp;rdquo; or timeout error&lt;/td&gt;
&lt;td&gt;Order still in &lt;code&gt;PENDING_PAYMENT&lt;/code&gt; status&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;User creates a new order&lt;/td&gt;
&lt;td&gt;Original order still active in database&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;User assumes order failed&lt;/td&gt;
&lt;td&gt;System still waiting for payment confirmation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Payment confirmed late (after timeout)&lt;/td&gt;
&lt;td&gt;Conflict: order already considered failed by client&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="real-world-impact"&gt;Real-World Impact
&lt;/h3&gt;&lt;p&gt;This inconsistency leads to several critical problems across different system types. As an example, in an e-commerce system:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ghost Orders&lt;/strong&gt;: Orders that appear failed to users but remain active in the system&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Double Payment Processing&lt;/strong&gt;: A payment might be confirmed for an order that the user believes has already failed, leading to confusion&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Integrity Issues&lt;/strong&gt;: The system state becomes inconsistent, making it difficult to track actual order status&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;User Trust Erosion&lt;/strong&gt;: Users experience unreliable behavior, damaging confidence in the platform&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Debugging Complexity&lt;/strong&gt;: Production issues become difficult to trace because the failure is silent and state-dependent&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Similar issues can occur in any system that relies on in-memory timeout mechanisms—ride-sharing platforms, job scheduling systems, booking systems, and more all face the same fundamental risk.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="root-cause-analysis"&gt;Root Cause Analysis
&lt;/h2&gt;&lt;p&gt;The fundamental problem is architectural: &lt;strong&gt;systems that rely entirely on in-memory timeout mechanisms lack persistence or recovery strategy&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id="key-issues"&gt;Key Issues
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;No State Persistence&lt;/strong&gt;: The timeout state exists only in memory. When the JVM terminates, this state is lost forever.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;No Graceful Shutdown Handling&lt;/strong&gt;: Applications don&amp;rsquo;t handle shutdown signals to complete pending timeout operations before termination.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;No Recovery Mechanism&lt;/strong&gt;: There&amp;rsquo;s no background process to detect and recover operations that should have timed out but didn&amp;rsquo;t. In an e-commerce system, for example, orders that should have timed out remain in an intermediate state.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tight Coupling&lt;/strong&gt;: The timeout logic is tightly coupled to the application lifecycle. When the application dies, the timeout dies with it.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="why-virtual-threads-dont-help-here"&gt;Why Virtual Threads Don&amp;rsquo;t Help Here
&lt;/h3&gt;&lt;p&gt;While virtual threads are excellent for handling many concurrent operations efficiently, they don&amp;rsquo;t solve the fundamental problem of persistence. Virtual threads are still in-memory constructs that disappear when the JVM terminates. The solution requires moving the timeout mechanism outside of the application&amp;rsquo;s memory space.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="the-solution-persistent-timeout-mechanism"&gt;The Solution: Persistent Timeout Mechanism
&lt;/h2&gt;&lt;p&gt;In our next article, we&amp;rsquo;ll explore how to solve this problem by implementing a &lt;strong&gt;persistent timeout mechanism using Redis Sorted Sets (ZSET)&lt;/strong&gt; combined with a &lt;strong&gt;recovery worker pattern&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This approach ensures that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Timeout state is persisted outside the application memory&lt;/li&gt;
&lt;li&gt;Timeouts survive pod restarts and deployments&lt;/li&gt;
&lt;li&gt;A dedicated worker process can recover and process missed timeouts&lt;/li&gt;
&lt;li&gt;Systems maintain consistency even during infrastructure changes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The solution leverages Redis ZSET&amp;rsquo;s ability to store timeout timestamps as scores, allowing efficient querying of expired timeouts, while a background worker continuously processes these timeouts regardless of which pod originally created them. This pattern applies to e-commerce systems, ride-sharing platforms, job schedulers, and any other system requiring reliable timeout handling.&lt;/p&gt;
&lt;p&gt;Stay tuned for the detailed implementation in the next post!&lt;/p&gt;</description></item></channel></rss>